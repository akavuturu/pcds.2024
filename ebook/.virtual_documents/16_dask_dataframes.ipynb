


import dask.dataframe as dd
df = dd.read_csv('./data/nycflight/*.csv',
                 dtype={'TailNum': str,
                        'CRSElapsedTime': float,
                        'Cancelled': bool})
df


df.tail()


df.head()





df2 = df[df.TailNum=='N516UA'].compute()
df2





routes = df[['FlightNum','TailNum']].compute()

routes





#routes.groupby('TailNum').FlightNum.count()
routes.groupby('TailNum')['FlightNum'].count()





routes.groupby('FlightNum')['TailNum'].count()





routes.groupby('TailNum')['FlightNum'].count().max()





routes.groupby('FlightNum')['TailNum'].count().max()





routes.groupby('FlightNum').TailNum.count().idxmax()


routes.groupby('TailNum').FlightNum.count().idxmax()





routes[routes.TailNum != 'UNKNOW'].groupby('TailNum').FlightNum.count().idxmax()





routes[routes.TailNum != 'UNKNOW'].groupby('TailNum').FlightNum.count().max()


type(routes)





routecount = routes.groupby('TailNum').FlightNum.count()
routecount.get('N413DA')


type(routecount)





type(routecount)





print(df.index, "\n")
print("Number of rows in the database\n", len(df))
maxindex = df.index.nunique().compute()
print("Number of unique values in the index\n", maxindex)

# find all entries with index value 22000
df.loc[22000].compute()


df.index.head()








df = dd.read_csv('/tmp/csv*.csv')
df.head
df.compute()





%time df.groupby('A').sum().compute()


%time df.groupby('B').sum().compute()





df = dd.read_csv('/tmp/csv*.csv')
%time df = df.set_index('A').compute()
df


%time df.groupby('A').sum()


df = dd.read_csv('/tmp/csv*.csv')
%time df = df.set_index('B').compute()
df


%time df.groupby('B').sum()














import csv
for i in range(100):
    with open(f'/tmp/csv{i}.csv', 'w', newline='') as csvfile:
        csvw = csv.writer(csvfile, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
        csvw.writerow(['A','B'])
        for j in range(500000):
            csvw.writerow([i,j])



