{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d75c8ac9-b947-4dc9-9eb8-3bcd2c9662eb",
   "metadata": {},
   "source": [
    "### Activity 6: Communicating Ray Actors\n",
    "\n",
    "(due due Monday December 9, 2024 4:00 pm)\n",
    "\n",
    "This is a short exercise to demonstrate how actors can communicate through remote oids.\n",
    "We are going to break the actors of the ImageNet classification [Example 24](../../examples/24_ex_ray_actors.ipynb) into \n",
    "two actors: one that transforms the image into an ResNet50 compatible tensor and one that takes\n",
    "the tensor as input and returns the classification. \n",
    "\n",
    "You have been given two class files that have been written to be instantiated as Ray actors:\n",
    "  * [rayresnet50_normalize](./rayresnet50_normalize.py)\n",
    "  * [rayresnet50_classify](./rayresnet50_classify.py)\n",
    "\n",
    "To complete the exercise you need to populate the following driver code.  Then answer the questions.\n",
    "\n",
    "Data is from https://github.com/EliSchwartz/imagenet-sample-images.\n",
    "\n",
    "Note: check your ouput to make sure that the predictions match the input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f39ff1e-03fe-4853-8039-d2dea50c019f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 17:07:16,073\tINFO worker.py:1652 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  426.4795763492584  seconds\n",
      "Error rate: 0.0170\n"
     ]
    }
   ],
   "source": [
    "from rayresnet50_normalize import RRN50Normalize\n",
    "from rayresnet50_classify import RRN50Classify\n",
    "import ray\n",
    "import time\n",
    "import os\n",
    "\n",
    "num_actors=4\n",
    "\n",
    "# script to drive parallel program\n",
    "ray.init(num_cpus=num_actors, ignore_reinit_error=True)\n",
    "\n",
    "### TODO instantiate 4 normalization actors\n",
    "normalize_actors = [RRN50Normalize.remote() for _ in range(num_actors)]\n",
    "\n",
    "### TODO instantiate 4 classification actors\n",
    "classify_actors = [RRN50Classify.remote() for _ in range(num_actors)]\n",
    "\n",
    "directory = '../../data/imagenet1000'\n",
    "files = os.listdir(directory)\n",
    "\n",
    "start_time = time.time()  # Get the current time\n",
    "\n",
    "normalize_oids = []\n",
    "classify_oids = []\n",
    "\n",
    "for i in range(len(files)):\n",
    "    if files[i].endswith(\".JPEG\"):\n",
    "        file_path = os.path.join(directory, files[i])\n",
    "\n",
    "        ### TODO call remote to normalize image into tensor\n",
    "        normalize_actor = normalize_actors[i % num_actors]\n",
    "        norm_oid = normalize_actor.normalize_image.remote(file_path)\n",
    "    \n",
    "        ### TODO call remote to classify tensor\n",
    "        classify_actor = classify_actors[i % num_actors]\n",
    "        class_oid = classify_actor.classify_image.remote(norm_oid)\n",
    "        \n",
    "        ### TODO store the oids needed to complete the computation\n",
    "        normalize_oids.append((files[i], norm_oid))\n",
    "        classify_oids.append((files[i], class_oid))\n",
    "err = 0\n",
    "for i in range(len(files)):\n",
    "    try:\n",
    "        if files[i].endswith(\".JPEG\"):\n",
    "            ### TODO collect results for each file in a variable preds\n",
    "            file_name, class_oid = classify_oids[i]\n",
    "            preds = ray.get(class_oid)\n",
    "\n",
    "            parsed = file_name.split(\".\")[0].split(\"_\")[1:]\n",
    "            filename = \" \".join(parsed)\n",
    "            if filename not in preds: err += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "end_time = time.time()  # Get the current time again\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time: \", execution_time, \" seconds\")\n",
    "print(f\"Error rate: {(err / len(files)):0.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af699227-012d-495f-8a53-34db9e47bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f80ddb-2308-4a0f-970b-8121ab1de586",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "Please provide short answers (2-3 sentences) to the following questions.  Submit just the written answers (no code) to Gradescope.\n",
    "\n",
    "* Question 1: Does the computation for a single input file (normalization and classification) run in serial or parallel?  If serially, how is the dependency enforced?\n",
    "\n",
    "The computation runs in series, as the output of the normalization step is required for the classification step. Ray enforces this when we send the `norm_oid` into the remote call of the classification step, which tells Ray that we need to schedule the classification step after the normalization step is completed.\n",
    "\n",
    "* Question 2: Does the computation of different files run in serial or parallel?  If parallel, explain why they are independent.\n",
    "\n",
    "The computation for different files is run in parallel. With different Ray actors, we can handle the computation for different files independently, as each actor will work on their own file. Since the normalization of file A does not depend on the normalization or classification of file B, we can do these files in parallel using different actors.\n",
    "\n",
    "* Question 3: This version has about the same runtime as the version in Activity 22 that does normalization and classification in one actor.\n",
    "\n",
    "    * (part a) In what configuration would it be fast to do them together?\n",
    " \n",
    "      If you have a small dataset where the parallelism might not be as pronounced, then the overhead of using many actors would outweigh the speedup you gain. Additionally, if the tasks we are performing (normalization and classification) are not computationally expensive, then using only one actor could be better than splitting the work up and potentially leading to delays in the overall computation. In terms of target hardware, we would want to use only one actor when we have limited CPU/GPU resources, as we won't be able to take advantage of the multiple actors. \n",
    "      \n",
    "    * (part b) In what configuration would it be faster to do them separately?\n",
    "\n",
    "      Conversely, if we have a large dataset, we will see a significant speedup with using many actors, since the parallelism will be greater when working on multiple actors at once. Additionally, if the normalization/classification tasks are very expensive computationally, then we will want to split up the work among many actors to ensure that as much of the work is parallelized as possible. In terms of target hardware, we would want to use multiple actors when we have extensive compute resources, such as distributed/cloud compute, efficient GPUs, or even simply multi-core CPUs. Any improvement to the hardware can be directly translated to a speedup in the program if we match the number of actors to our available resources.\n",
    "\n",
    "(By configuration, I mean data properties or target hardware system on which this would be preferable.) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
