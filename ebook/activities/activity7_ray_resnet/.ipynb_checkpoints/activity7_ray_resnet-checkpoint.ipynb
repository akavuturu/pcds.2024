{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d75c8ac9-b947-4dc9-9eb8-3bcd2c9662eb",
   "metadata": {},
   "source": [
    "### Activity 7: Communicating Ray Actors\n",
    "\n",
    "(due due Friday December 8, 2023 5:00 pm)\n",
    "\n",
    "This is a short exercise to demonstrate how actors can communicate through remote oids.\n",
    "We are going to break the actors of the ImageNet classification [Example 24](../../examples/24_ex_ray_actors.ipynb) into \n",
    "two actors: one that transforms the image into an ResNet50 compatible tensor and one that takes\n",
    "the tensor as input and returns the classification. \n",
    "\n",
    "You have been given two class files that have been written to be instantiated as Ray actors:\n",
    "  * [rayresnet50_normalize](./rayresnet50_normalize.py)\n",
    "  * [rayresnet50_classify](./rayresnet50_classify.py)\n",
    "\n",
    "To complete the exercise you need to populate the following driver code.  Then answer the questions.\n",
    "\n",
    "Data is from https://github.com/EliSchwartz/imagenet-sample-images.\n",
    "\n",
    "Note: check your ouput to make sure that the predictions match the input file. This classifier should be over 90% correct. You need to be careful to match the return OIDs with files. **Include the cell output in submitted notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5976c-e006-4192-92ba-345127b5f00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch==2.5.1 (from torchvision)\n",
      "  Downloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (2024.3.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch==2.5.1->torchvision)\n",
      "  Downloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch==2.5.1->torchvision) (69.5.1)\n",
      "Collecting sympy==1.13.1 (from torch==2.5.1->torchvision)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch==2.5.1->torchvision) (2.1.3)\n",
      "Downloading torchvision-0.20.1-cp312-cp312-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m906.2/906.4 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m00:02\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f39ff1e-03fe-4853-8039-d2dea50c019f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 22:20:16,811\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.8.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrayresnet50_normalize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RRN50Normalize\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrayresnet50_classify\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RRN50Classify\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\n",
      "File \u001b[0;32m~/ebook/activities/activity7_ray_resnet/rayresnet50_normalize.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resnet50, ResNet50_Weights\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pil_to_tensor\n\u001b[1;32m      6\u001b[0m \u001b[38;5;129m@ray\u001b[39m\u001b[38;5;241m.\u001b[39mremote\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRRN50Normalize\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from rayresnet50_normalize import RRN50Normalize\n",
    "from rayresnet50_classify import RRN50Classify\n",
    "import ray\n",
    "import time\n",
    "import os\n",
    "\n",
    "num_actors=4\n",
    "\n",
    "# script to drive parallel program\n",
    "ray.init(num_cpus=num_actors, ignore_reinit_error=True)\n",
    "\n",
    "### TODO instantiate 4 normalization actors\n",
    "normalize_actors = [RRN50Normalize.remote() for _ in range(num_actors)]\n",
    "\n",
    "### TODO instantiate 4 classification actors\n",
    "classify_actors = [RRN50Classify.remote() for _ in range(num_actors)]\n",
    "\n",
    "directory = '../../data/imagenet1000'\n",
    "files = os.listdir(directory)\n",
    "\n",
    "classify_oids = {}\n",
    "\n",
    "start_time = time.time()  # Get the current time\n",
    "\n",
    "for i in range(len(files)):\n",
    "    if files[i].endswith(\".JPEG\"):\n",
    "        file_path = os.path.join(directory, files[i])\n",
    "\n",
    "        ### TODO call remote to normalize image into tensor\n",
    "        normalized_img = normalize_actors[i % num_actors].normalize_image.remote(file_path)\n",
    "        \n",
    "        ### TODO call remote to classify tensor\n",
    "        classify_oid = classify_actors[i % num_actors].classify_image.remote(normalized_img)\n",
    "        \n",
    "        ### TODO store the oids needed to complete the computation\n",
    "        classify_oids[filename] = classify_oid\n",
    "        \n",
    "for i, filename in enumerate(os.listdir(directory)):\n",
    "    try:\n",
    "        preds = ray.get(classify_oids[filename])\n",
    "        print(f\"Filename {[filename]}: predictions {preds}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in retrieving results for file {filename}: {e}\")\n",
    "\n",
    "end_time = time.time()  # Get the current time again\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time: \", execution_time, \" seconds\")\n",
    "ray.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f80ddb-2308-4a0f-970b-8121ab1de586",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "* Question 1: Does the computation for a single input file (normalization and classification) run in serial or parallel?  If serially, how is the dependency enforced?\n",
    "\n",
    "Each file is normalized and classified serially, as the classifier requires the `normalize_oid` as an input to the `classify_image` function. The dependency is enfored \n",
    "\n",
    "* Question 2: Does the computation of different files run in serial or parallel?  If parallel, explain why they are independent. \n",
    "\n",
    "* Question 3: Your computation needs to collect return identifiers for the classification objects. It is not necessary to collect the OIDs of the normalization function in the driver code. Why?\n",
    "\n",
    "* Question 4: At any given point in time, how many actors are running and what are they doing?\n",
    "\n",
    "* Question 5: Is this implementation faster or slower than doing the normalization and classification in one actor?  Can you think of a situation in which it would be faster to do them together?  (By situation, I mean data properties or target hardware system on which this would be preferable.) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
